{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11495578,"sourceType":"datasetVersion","datasetId":7195832}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport yaml\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet50, ResNet50_Weights, vit_b_16, ViT_B_16_Weights\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom IPython.display import FileLink\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Configuration\nDATA_PATH = \"/kaggle/input/8-facial-expressions-for-yolo/9 Facial Expressions you need\"\nBATCH_SIZE = 32\nEPOCHS = 30\nLR = 0.0005\nIMG_SIZE = 224\nNUM_CLASSES = 9\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Emotion labels\nemotion_labels = {\n    0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear',\n    4: 'Happy', 5: 'Natural', 6: 'Sad', 7: 'Sleepy', 8: 'Surprised'\n}\n\nclass FocalLoss(torch.nn.Module):\n    def __init__(self, alpha=None, gamma=2.0):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def forward(self, inputs, targets):\n        ce_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        loss = (1 - pt)**self.gamma * ce_loss\n        if self.alpha is not None:\n            loss = self.alpha[targets] * loss\n        return loss.mean()\n\n# Load YAML config\nwith open(os.path.join(DATA_PATH, 'data.yaml')) as f:\n    data_config = yaml.safe_load(f)\nprint(\"Classes from YAML:\", data_config['names'])\n\nclass YoloEmotionDataset(Dataset):\n    def __init__(self, base_path, image_paths, label_paths, transform=None):\n        self.base_path = base_path\n        self.image_paths = image_paths\n        self.label_paths = label_paths\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.base_path, self.image_paths[idx])\n        label_path = os.path.join(self.base_path, self.label_paths[idx])\n        \n        image = Image.open(img_path).convert('RGB')\n        \n        with open(label_path, 'r') as f:\n            lines = f.readlines()\n            class_id = int(lines[0].split()[0]) if len(lines) > 0 else 5  # Default to Neutral\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, class_id\n\ndef collect_paths(base_path, mode='train'):\n    images_dir = os.path.join(base_path, mode, 'images')\n    labels_dir = os.path.join(base_path, mode, 'labels')\n    \n    return [\n        (f\"{mode}/images/{img_file}\", f\"{mode}/labels/{img_file.rsplit('.', 1)[0]}.txt\")\n        for img_file in os.listdir(images_dir)\n        if img_file.lower().endswith(('.png', '.jpg', '.jpeg'))\n        and os.path.exists(os.path.join(labels_dir, img_file.rsplit('.', 1)[0] + '.txt'))\n    ]\n\n# Enhanced augmentation\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    transforms.GaussianBlur(kernel_size=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Data collection\ntrain_paths = collect_paths(DATA_PATH, 'train')\nval_paths = collect_paths(DATA_PATH, 'valid')\n\ntrain_image_paths, train_label_paths = zip(*train_paths) if train_paths else ([], [])\nval_image_paths, val_label_paths = zip(*val_paths) if val_paths else ([], [])\n\nprint(f\"Found {len(train_image_paths)} training images\")\nprint(f\"Found {len(val_image_paths)} validation images\")\n\ntrain_dataset = YoloEmotionDataset(DATA_PATH, train_image_paths, train_label_paths, train_transform)\nval_dataset = YoloEmotionDataset(DATA_PATH, val_image_paths, val_label_paths, val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\ndef initialize_model(model_name='resnet50'):\n    if model_name == 'resnet50':\n        model = resnet50(weights=ResNet50_Weights.DEFAULT)\n        model.fc = torch.nn.Sequential(\n            torch.nn.Dropout(0.5),\n            torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n        )\n    elif model_name == 'vit':\n        model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n        model.heads.head = torch.nn.Sequential(\n            torch.nn.Dropout(0.5),\n            torch.nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n        )\n    return model.to(device)\n\nmodel = initialize_model('resnet50')\n\n# Calculate class weights\nclass_counts = np.zeros(NUM_CLASSES)\nfor _, label in train_dataset:\n    class_counts[label] += 1\nclass_weights = 1. / (class_counts + 1e-6)\nclass_weights = class_weights / class_weights.sum()\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\ncriterion = FocalLoss(alpha=class_weights, gamma=2.0)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)\n\ndef train_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss, correct, total = 0, 0, 0\n    \n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    return total_loss / len(loader), 100 * correct / total\n\ndef validate(model, loader, criterion):\n    model.eval()\n    total_loss, correct, total = 0, 0, 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    if len(np.unique(all_labels)) > 1:\n        print(\"\\nClassification Report:\")\n        print(classification_report(all_labels, all_preds, target_names=emotion_labels.values()))\n    \n    return total_loss / len(loader), 100 * correct / total\n\n# Training with logging\nbest_val_acc = 0\npatience = 5\nno_improve = 0\nlr_history = []\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = validate(model, val_loader, criterion)\n    \n    scheduler.step(val_acc)\n    current_lr = optimizer.param_groups[0]['lr']\n    lr_history.append(current_lr)\n    \n    print(f\"Epoch {epoch+1}/{EPOCHS}: \"\n          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | \"\n          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}% | \"\n          f\"LR: {current_lr:.2e}\")\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n        no_improve = 0\n    else:\n        no_improve += 1\n        if no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n# Load best model\nmodel.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n\n# Testing\ntest_paths = collect_paths(DATA_PATH, 'test')\nif test_paths:\n    test_image_paths, test_label_paths = zip(*test_paths)\n    test_dataset = YoloEmotionDataset(DATA_PATH, test_image_paths, test_label_paths, val_transform)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    test_loss, test_acc = validate(model, test_loader, criterion)\n    print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n\nFileLink('/kaggle/working/best_model.pth')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:49:09.535097Z","iopub.execute_input":"2025-08-27T04:49:09.535727Z","iopub.status.idle":"2025-08-27T07:46:58.473781Z","shell.execute_reply.started":"2025-08-27T04:49:09.535701Z","shell.execute_reply":"2025-08-27T07:46:58.472060Z"}},"outputs":[{"name":"stdout","text":"Classes from YAML: ['angry', 'contempt', 'disgust', 'fear', 'happy', 'natural', 'sad', 'sleepy', 'surprised']\nFound 64864 training images\nFound 1720 validation images\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 197MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.75      0.45      0.56       258\n    Contempt       0.41      0.68      0.52        82\n     Disgust       0.48      0.68      0.56       108\n        Fear       0.44      0.77      0.56       107\n       Happy       0.84      0.78      0.81       387\n     Natural       0.47      0.60      0.53       172\n         Sad       0.71      0.53      0.61       312\n      Sleepy       0.53      0.87      0.66        38\n   Surprised       0.77      0.67      0.72       256\n\n    accuracy                           0.64      1720\n   macro avg       0.60      0.67      0.61      1720\nweighted avg       0.68      0.64      0.64      1720\n\nEpoch 1/30: Train Loss: 0.0510, Acc: 49.08% | Val Loss: 0.0335, Acc: 63.90% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.65      0.56      0.60       258\n    Contempt       0.40      0.78      0.53        82\n     Disgust       0.40      0.78      0.53       108\n        Fear       0.62      0.70      0.66       107\n       Happy       0.84      0.85      0.84       387\n     Natural       0.49      0.60      0.54       172\n         Sad       0.79      0.43      0.56       312\n      Sleepy       0.58      0.97      0.73        38\n   Surprised       0.87      0.59      0.70       256\n\n    accuracy                           0.65      1720\n   macro avg       0.63      0.70      0.63      1720\nweighted avg       0.71      0.65      0.66      1720\n\nEpoch 2/30: Train Loss: 0.0360, Acc: 60.60% | Val Loss: 0.0314, Acc: 65.17% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.68      0.57      0.62       258\n    Contempt       0.54      0.60      0.57        82\n     Disgust       0.56      0.69      0.62       108\n        Fear       0.44      0.83      0.58       107\n       Happy       0.90      0.79      0.84       387\n     Natural       0.54      0.59      0.57       172\n         Sad       0.74      0.60      0.66       312\n      Sleepy       0.57      0.95      0.71        38\n   Surprised       0.78      0.71      0.74       256\n\n    accuracy                           0.68      1720\n   macro avg       0.64      0.70      0.66      1720\nweighted avg       0.71      0.68      0.69      1720\n\nEpoch 3/30: Train Loss: 0.0321, Acc: 64.02% | Val Loss: 0.0291, Acc: 68.20% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.75      0.53      0.63       258\n    Contempt       0.53      0.68      0.60        82\n     Disgust       0.63      0.73      0.68       108\n        Fear       0.60      0.80      0.69       107\n       Happy       0.90      0.81      0.85       387\n     Natural       0.52      0.78      0.62       172\n         Sad       0.74      0.59      0.66       312\n      Sleepy       0.64      0.97      0.77        38\n   Surprised       0.76      0.73      0.75       256\n\n    accuracy                           0.71      1720\n   macro avg       0.68      0.74      0.69      1720\nweighted avg       0.73      0.71      0.71      1720\n\nEpoch 4/30: Train Loss: 0.0296, Acc: 66.07% | Val Loss: 0.0260, Acc: 70.81% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.78      0.59      0.68       258\n    Contempt       0.46      0.61      0.53        82\n     Disgust       0.53      0.78      0.63       108\n        Fear       0.61      0.79      0.69       107\n       Happy       0.90      0.80      0.84       387\n     Natural       0.55      0.65      0.60       172\n         Sad       0.69      0.72      0.70       312\n      Sleepy       0.74      0.97      0.84        38\n   Surprised       0.90      0.69      0.78       256\n\n    accuracy                           0.72      1720\n   macro avg       0.68      0.73      0.70      1720\nweighted avg       0.74      0.72      0.72      1720\n\nEpoch 5/30: Train Loss: 0.0277, Acc: 67.97% | Val Loss: 0.0245, Acc: 71.51% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.64      0.75      0.69       258\n    Contempt       0.53      0.72      0.61        82\n     Disgust       0.67      0.52      0.59       108\n        Fear       0.66      0.67      0.67       107\n       Happy       0.96      0.78      0.86       387\n     Natural       0.57      0.73      0.64       172\n         Sad       0.76      0.69      0.72       312\n      Sleepy       0.71      0.95      0.81        38\n   Surprised       0.81      0.79      0.80       256\n\n    accuracy                           0.73      1720\n   macro avg       0.70      0.73      0.71      1720\nweighted avg       0.75      0.73      0.74      1720\n\nEpoch 6/30: Train Loss: 0.0263, Acc: 69.07% | Val Loss: 0.0245, Acc: 73.26% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.83      0.59      0.69       258\n    Contempt       0.51      0.74      0.61        82\n     Disgust       0.64      0.63      0.64       108\n        Fear       0.61      0.80      0.69       107\n       Happy       0.92      0.82      0.87       387\n     Natural       0.53      0.71      0.61       172\n         Sad       0.78      0.62      0.69       312\n      Sleepy       0.90      0.97      0.94        38\n   Surprised       0.72      0.86      0.78       256\n\n    accuracy                           0.73      1720\n   macro avg       0.72      0.75      0.72      1720\nweighted avg       0.76      0.73      0.73      1720\n\nEpoch 7/30: Train Loss: 0.0249, Acc: 70.25% | Val Loss: 0.0243, Acc: 73.08% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.81      0.58      0.67       258\n    Contempt       0.54      0.55      0.55        82\n     Disgust       0.62      0.76      0.68       108\n        Fear       0.65      0.73      0.69       107\n       Happy       0.93      0.82      0.87       387\n     Natural       0.56      0.74      0.64       172\n         Sad       0.76      0.72      0.74       312\n      Sleepy       0.75      0.95      0.84        38\n   Surprised       0.76      0.86      0.80       256\n\n    accuracy                           0.74      1720\n   macro avg       0.71      0.74      0.72      1720\nweighted avg       0.76      0.74      0.74      1720\n\nEpoch 8/30: Train Loss: 0.0235, Acc: 71.50% | Val Loss: 0.0257, Acc: 74.30% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.86      0.57      0.68       258\n    Contempt       0.50      0.73      0.60        82\n     Disgust       0.52      0.79      0.62       108\n        Fear       0.70      0.69      0.69       107\n       Happy       0.93      0.85      0.89       387\n     Natural       0.58      0.72      0.64       172\n         Sad       0.77      0.74      0.76       312\n      Sleepy       0.74      0.97      0.84        38\n   Surprised       0.83      0.80      0.82       256\n\n    accuracy                           0.75      1720\n   macro avg       0.72      0.76      0.73      1720\nweighted avg       0.78      0.75      0.75      1720\n\nEpoch 9/30: Train Loss: 0.0228, Acc: 72.14% | Val Loss: 0.0233, Acc: 75.00% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.75      0.74      0.75       258\n    Contempt       0.44      0.83      0.57        82\n     Disgust       0.68      0.73      0.71       108\n        Fear       0.61      0.86      0.71       107\n       Happy       0.97      0.80      0.88       387\n     Natural       0.69      0.48      0.57       172\n         Sad       0.75      0.74      0.75       312\n      Sleepy       0.84      0.97      0.90        38\n   Surprised       0.79      0.78      0.79       256\n\n    accuracy                           0.75      1720\n   macro avg       0.73      0.77      0.73      1720\nweighted avg       0.77      0.75      0.75      1720\n\nEpoch 10/30: Train Loss: 0.0222, Acc: 72.70% | Val Loss: 0.0232, Acc: 75.06% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.79      0.76      0.77       258\n    Contempt       0.52      0.67      0.59        82\n     Disgust       0.60      0.67      0.63       108\n        Fear       0.71      0.78      0.74       107\n       Happy       0.94      0.86      0.89       387\n     Natural       0.56      0.67      0.61       172\n         Sad       0.77      0.76      0.76       312\n      Sleepy       0.88      0.92      0.90        38\n   Surprised       0.88      0.76      0.82       256\n\n    accuracy                           0.77      1720\n   macro avg       0.74      0.76      0.75      1720\nweighted avg       0.78      0.77      0.77      1720\n\nEpoch 11/30: Train Loss: 0.0214, Acc: 73.66% | Val Loss: 0.0233, Acc: 76.63% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.80      0.68      0.74       258\n    Contempt       0.53      0.71      0.60        82\n     Disgust       0.56      0.78      0.65       108\n        Fear       0.66      0.77      0.71       107\n       Happy       0.92      0.87      0.90       387\n     Natural       0.57      0.62      0.59       172\n         Sad       0.75      0.71      0.73       312\n      Sleepy       0.88      0.97      0.93        38\n   Surprised       0.85      0.75      0.80       256\n\n    accuracy                           0.75      1720\n   macro avg       0.73      0.76      0.74      1720\nweighted avg       0.77      0.75      0.76      1720\n\nEpoch 12/30: Train Loss: 0.0206, Acc: 74.40% | Val Loss: 0.0222, Acc: 75.35% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.83      0.67      0.74       258\n    Contempt       0.54      0.72      0.61        82\n     Disgust       0.75      0.68      0.71       108\n        Fear       0.62      0.83      0.71       107\n       Happy       0.89      0.88      0.88       387\n     Natural       0.59      0.77      0.67       172\n         Sad       0.83      0.74      0.78       312\n      Sleepy       0.92      0.95      0.94        38\n   Surprised       0.86      0.79      0.82       256\n\n    accuracy                           0.78      1720\n   macro avg       0.76      0.78      0.76      1720\nweighted avg       0.79      0.78      0.78      1720\n\nEpoch 13/30: Train Loss: 0.0200, Acc: 74.69% | Val Loss: 0.0221, Acc: 77.62% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.78      0.63      0.70       258\n    Contempt       0.45      0.88      0.60        82\n     Disgust       0.68      0.69      0.69       108\n        Fear       0.69      0.77      0.73       107\n       Happy       0.88      0.86      0.87       387\n     Natural       0.64      0.63      0.64       172\n         Sad       0.74      0.77      0.75       312\n      Sleepy       0.78      0.95      0.86        38\n   Surprised       0.89      0.72      0.80       256\n\n    accuracy                           0.75      1720\n   macro avg       0.73      0.77      0.74      1720\nweighted avg       0.77      0.75      0.76      1720\n\nEpoch 14/30: Train Loss: 0.0195, Acc: 75.31% | Val Loss: 0.0220, Acc: 75.17% | LR: 5.00e-04\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       Angry       0.81      0.69      0.74       258\n    Contempt       0.52      0.70      0.60        82\n     Disgust       0.58      0.83      0.68       108\n        Fear       0.65      0.80      0.72       107\n       Happy       0.89      0.86      0.87       387\n     Natural       0.60      0.69      0.64       172\n         Sad       0.83      0.72      0.77       312\n      Sleepy       0.72      0.95      0.82        38\n   Surprised       0.90      0.75      0.82       256\n\n    accuracy                           0.76      1720\n   macro avg       0.72      0.78      0.74      1720\nweighted avg       0.78      0.76      0.77      1720\n\nEpoch 15/30: Train Loss: 0.0191, Acc: 75.70% | Val Loss: 0.0217, Acc: 76.34% | LR: 5.00e-04\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1124694812.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1124694812.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}